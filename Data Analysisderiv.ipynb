{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a library for datasets\n",
    "import pandas as pd\n",
    "\n",
    "DATASET = 'WBI'\n",
    "N_sets = 6\n",
    "# DATASET = 'RIMPVC'\n",
    "# N_sets = 5\n",
    "\n",
    "def traces(i):\n",
    "    \"\"\"Get traces of dataset @i\"\"\"\n",
    "    return pd.read_csv('data/WBI%s.csv' % i, index_col=0)\n",
    "\n",
    "def derivs(i):\n",
    "    '''Get derivatives of dataset @i'''\n",
    "    return pd.read_csv('data/dWBI%s.csv' % i, index_col=0)\n",
    "\n",
    "# Some code for later\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "minmax = MinMaxScaler()\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "meanstd = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t0 = derivs(0)\n",
    "print(t0.shape)\n",
    "print(t0.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traces on single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "#Define the function for plotting traces\n",
    "def plot_all_traces(df, scaler=None):\n",
    "    '''Plot all traces of dataset @df'''\n",
    "    plt.figure(figsize=(20,30))\n",
    "    if scaler is not None:\n",
    "        df = pd.DataFrame(scaler.fit_transform(df.values), columns=df.columns, index=df.index)\n",
    "    traces = df.values.copy()\n",
    "    stretch = 2\n",
    "    N = traces.shape[1]//2\n",
    "    for i in range(traces.shape[1]):\n",
    "        traces[:,i] += stretch * (i - N * (i > N-1))\n",
    "    t1 = traces[:,:N]\n",
    "    t2 = traces[:,N:]\n",
    "    plt.subplot(121)\n",
    "    plt.plot(t1, linewidth=1)\n",
    "    plt.yticks(np.arange(0,N*stretch,stretch),labels=df.columns[:N])\n",
    "    plt.subplot(122)\n",
    "    plt.plot(t2, linewidth=1)\n",
    "    plt.yticks(np.arange(0,N*stretch,stretch),labels=df.columns[N:])\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function for 1 dataset \n",
    "plot_all_traces(t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap on single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Some colormaps\n",
    "COLOR_MAPS = ['seismic', 'jet', 'Reds', 'flag']\n",
    "\n",
    "#Define the function for plotting as a heatmap\n",
    "def heatmap(df, scaler=None, cmap='flag'):\n",
    "    '''\n",
    "    Plot traces of df as a heatmap, \n",
    "    using @scaler for scaling \n",
    "    and @cmap for colors\n",
    "    '''\n",
    "    plt.figure(figsize=(20,30))\n",
    "    if scaler is not None:\n",
    "        df = pd.DataFrame(scaler.fit_transform(df.values), columns=df.columns, index=df.index)\n",
    "    sns.heatmap(df.T, cmap=cmap, cbar_kws={\"shrink\": .5})\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below and look at the result.  \n",
    "The heatmap is obviously pretty unreadable, why ?  \n",
    "Why not looking at this https://matplotlib.org/users/colormaps.html ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call the function for 1 dataset\n",
    "heatmap(t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of different scaling strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NS = ['AVAL', 'AVBL']\n",
    "\n",
    "def compare_norm(neurons=NS):\n",
    "    \"\"\"Compare the influence of different normalization methods on @neurons\"\"\"\n",
    "    def plot_avab(df=t0, scaler=None):\n",
    "        if scaler is not None:\n",
    "            df = pd.DataFrame(scaler.fit_transform(df.values), columns=df.columns, index=df.index)\n",
    "        for n in neurons:\n",
    "            plt.plot(df[n], label=n)\n",
    "        plt.legend()\n",
    "        \n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('Raw data')\n",
    "    plot_avab()\n",
    "    plt.subplot(132)\n",
    "    plt.title('Min Max')\n",
    "    plot_avab(scaler=minmax)\n",
    "    plt.subplot(133)\n",
    "    plt.title('Mean std')\n",
    "    plot_avab(scaler=meanstd)\n",
    "    plt.show()\n",
    "    \n",
    "compare_norm()\n",
    "compare_norm(['AVAL', 'BAGL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_names = set()\n",
    "for i in range(N_sets):\n",
    "    all_names = all_names.union(set(traces(i).columns))\n",
    "LABELLED = [n  for n in all_names if any(c.isalpha() for c in n)]\n",
    "LABELLED = sorted(LABELLED)\n",
    "LABELLED.remove('bullshit')\n",
    "LABELLED.remove('bullshit.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def comp_amp(func, neur=LABELLED, stretch=1.7, scaler=None, title=''):\n",
    "    '''\n",
    "    Plot traces of neurons @neur \n",
    "    from data given by @func accross datasets\n",
    "    @stretch defines the separation between traces\n",
    "    @scaler defines the scaling for transforming the data\n",
    "    @title will be the title of the figure\n",
    "    '''\n",
    "    t = 0\n",
    "    N = len(neur)\n",
    "    cmap = plt.cm.get_cmap('tab10')\n",
    "    plt.figure(figsize=(45,30))\n",
    "    for i in range(N_sets):\n",
    "        df = func(i)\n",
    "        if scaler is not None:\n",
    "            df = pd.DataFrame(scaler.fit_transform(df.values), columns=df.columns, index=df.index)\n",
    "        for j, n in enumerate(neur):\n",
    "            try:\n",
    "                plt.plot(t + df.index, df[n] + j*stretch, color=cmap(j%10))\n",
    "            except:\n",
    "                pass\n",
    "        t += df.index[-1]\n",
    "        plt.axvline(t, color='k', linestyle='--')\n",
    "    \n",
    "    plt.yticks(np.arange(0,N*stretch,stretch),labels=neur)   \n",
    "    plt.tick_params(labeltop=False, labelright=True)\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.show()\n",
    "            \n",
    "comp_amp(traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence of different scaling strategies over datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_norm(neurons):\n",
    "    \"\"\"Compare the influence of different normalization methods on @neurons accross datasets\"\"\"\n",
    "    def plot_avab(df=t0, scaler=None):\n",
    "        t = 0\n",
    "        stretch = 2\n",
    "        cmap = plt.cm.get_cmap('tab10')\n",
    "        for i in range(N_sets):\n",
    "            df = traces(i)\n",
    "            if scaler is not None:\n",
    "                df = pd.DataFrame(scaler.fit_transform(df.values), columns=df.columns, index=df.index)\n",
    "            for j, n in enumerate(neurons):\n",
    "                try:\n",
    "                    plt.plot(t + df.index, df[n] + j*stretch, color=cmap(j%10))\n",
    "                except:\n",
    "                    pass\n",
    "            t += df.index[-1]\n",
    "            plt.axvline(t, color='k', linestyle='--')\n",
    "        \n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.subplot(311)\n",
    "    plt.title('Raw data')\n",
    "    plot_avab()\n",
    "    plt.subplot(312)\n",
    "    plt.title('Min Max')\n",
    "    plot_avab(scaler=minmax)\n",
    "    plt.subplot(313)\n",
    "    plt.title('Mean std')\n",
    "    plot_avab(scaler=meanstd)\n",
    "    plt.show()\n",
    "    \n",
    "compare_norm(['AVBL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Correlation and distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N0 = 'AVAL'\n",
    "N1 = 'AVAR'\n",
    "N2 = 'DVA'\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.scatterplot(t0[N0], t0[N1], label=N1)\n",
    "sns.scatterplot(t0[N0], t0[N2], label=N2)\n",
    "print('Correlation between %s and %s : %s' % (N0,N1,np.corrcoef(t0[N0], t0[N1])[0,1]))\n",
    "print('Correlation between %s and %s : %s' % (N0,N2,np.corrcoef(t0[N0], t0[N2])[0,1]))\n",
    "# plt.ylabel(\"$\\frac{dF}{F_0}$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation & distance matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "def get_labelled(df):\n",
    "    '''Return the name of labelled neurons in dataset @df'''\n",
    "    return [n  for n in df.columns if any(c.isalpha() for c in n)]\n",
    "\n",
    "def corr(df, vmin=None, vmax=None, cmap='flag'):\n",
    "    '''Compute and plot correlation matrix on @df'''\n",
    "    corr = df.corr()\n",
    "    heat(corr, vmin, vmax, cmap)\n",
    "\n",
    "def dist_comp(df):\n",
    "    distances = pdist(df.T.values, metric='euclidean')\n",
    "    return squareform(distances)\n",
    "def dist(df, vmin=None, vmax=None, cmap='flag'):\n",
    "    '''Compute and plot distance matrix on @df'''\n",
    "    dist = pd.DataFrame(dist_comp(df), columns = df.columns, index=df.columns)\n",
    "    heat(dist, vmin, vmax, cmap)\n",
    "    \n",
    "def heat(df, vmin=None, vmax=None, cmap='flag'):\n",
    "    f, ax = plt.subplots(figsize=(10, 10))\n",
    "    sns.heatmap(df, cmap=cmap, square=True, ax=ax, vmax=vmax, vmin=vmin, cbar_kws={\"shrink\": .5})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below and make it beautiful  \n",
    "Do you see a difference between the 2 matrices ?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot some matrices\n",
    "names = get_labelled(t0)\n",
    "corr(t0[names], cmap='flag')\n",
    "plt.show()\n",
    "dist(t0[names], cmap='flag')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from ipywidgets import interact\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib\n",
    "df = t0\n",
    "\n",
    "@interact(scaler=[None, minmax, meanstd], cmap=COLOR_MAPS)\n",
    "def pca(scaler=None, cmap='flag'):\n",
    "    '''Perform pca on @df'''\n",
    "    n = 10\n",
    "    if scaler is not None:\n",
    "        df2 = pd.DataFrame(scaler.fit_transform(df.values), columns=df.columns, index=df.index)\n",
    "    else:\n",
    "        df2 = df\n",
    "    pca = PCA(n_components=n, whiten=True)\n",
    "    pca.fit(df2)\n",
    "    columns = ['pca_%i' % i for i in range(n)]\n",
    "    df_pca = pd.DataFrame(pca.transform(df), columns=columns, index=df.index)\n",
    "    %matplotlib notebook\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    sns.scatterplot(x='pca_0', y='pca_1', data=df_pca, hue=df.index)\n",
    "    ax = fig.gca(projection='3d')\n",
    "    norm = matplotlib.colors.Normalize(0, df_pca.shape[0], clip=True)\n",
    "    mapper = matplotlib.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "    ax.scatter(df_pca['pca_0'], df_pca['pca_1'], df_pca['pca_2'], c=mapper.to_rgba(range(df_pca.shape[0])))\n",
    "    plt.axis('off')\n",
    "    plt.title('PCA transformation')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.barplot(np.arange(n), pca.explained_variance_ratio_)\n",
    "    plt.title('Amount of variance explained by components')\n",
    "    plt.xlabel('# component')\n",
    "    plt.ylabel('Proportion variance explained')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "df = t0.corr()\n",
    "\n",
    "@interact(method=['average', 'single', 'complete'], metric=['cityblock', 'euclidean'], ret=False)\n",
    "def clustmap(method='average', metric='cityblock', ret=True):\n",
    "    plt.figure(figsize = (15,15))\n",
    "    cg = sns.clustermap(df, metric=metric, method=method, vmin=-1, vmax=1, cmap=sns.diverging_palette(220, 10, as_cmap=True))\n",
    "    plt.show()\n",
    "    if ret:\n",
    "        return cg.dendrogram_col.reordered_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = df.columns[clustmap()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the traces and heatmap again using the clustering order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here :"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
